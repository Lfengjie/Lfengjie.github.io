---
layout: post
title: "librbd-源码分析"
date: 2020-6-28
description: "librbd 分析"
tag: 博客 
---

## 整体介绍
Ceph可以同时提供对象存储RGW、块存储RBD、文件系统存储Ceph FS。 RBD(RADOS Block Device)块设备类似磁盘可以被挂载。RBD块设备具有快照、多副本、克隆和一致性等特性，数据可以以条带化的方式存储到底层的Rados集群中。如果想从理论方面全面的了解rbd运作机制可以看：<Ceph设计原理与实现>一书

上层应用访问RBD块设备有两种途径，librbd 和 krbd:
- krbd:
集成在GNU/Linux内核的一个内核模块，用户用户态的rbd命令行工具可以将RBD块设备映射为本地的一个块设备文件。

- Librbd:
一个基于librados的用户态接口库（支持c, c++, python等），实现了对RBD的基本操作。Librbd 包含了rbd的相关操作，将Image进行分片（将一个 块 分解成 对象 进行处理，Ceph的底层本质还是对象存储）再存储到Rados集群中。

下图为rbd 架构图：

![rbd 架构图](/images/posts/rbd架构.png)

## 核心概念介绍
RBD是ceph中提供块存储的客户端服务，RBD基于librados API开发。Ceph底层的实现是对象存储，通过librbd实现了块存储的接口，对外提供块存储的服务。

### 名词介绍
- Image：
对应于LVM的Logical Volume，是能被attach/detach到VM的载体。在RBD中，Image的数据有多个Object组成。（image 镜像 可以作是块存储的呈现形式）

- Snapshot：
Image的某一个特定时刻的状态，只能读不能写但是可以将Image回滚到某一个Snapshot状态。Snapshot必定属于某一个Image。

- object：
后端Rados集群存储的单个对象，一个image会分拆成多个后端rados的对象，默认一个对象为4M，例如：一个大小为100M的image，后端对应的对象个数为25个。

- objectcacher：
一个object级别的缓存

### 操作
- Clone：为Image的某一个Snapshot的状态复制变成一个Image。如ImageA有一个Snapshot-1，clone是根据ImageA的Snapshot-1克隆得到ImageB。ImageB此时的状态与Snapshot-1完全一致，区别在于ImageB此时可写，并且拥有Image的相应能力。

### RBD元数据
RBD中的元数据包括image元数据和RBD管理元数据两种数据。在RADOS对象中有三种存储方式，根据RBD所支持或启动的功能特性的改变，RBD用于存储元数据的RADOS对象也会有所增减，所存储的元数据信息也会有所变化。
- 二进制（data）：
将元数据编码后以二进制文件的形式存储在RADOS对象的数据部分

- xattr：
将元数据以键值对的形式存储在RADOS对象的扩展属性中

- omap：
将元数据以键值对的形式存储在RADOS对象omap中

#### image元数据
单个image的元数据信息。

Rados对象名 | 元数据类型 | 描述
---|---|---
rbd_id.( name ) | data | 记录image名称到image id的单项映射关系，image内部元数据和数据的名称已id为基础，这样即使image重命名，内部的结构也基本不用发生改变。
rbd_header.( id ) | omap/xattr | 记录image所支持的功能特性、容量大小等基本信息以及配置参数、自定义元数据、锁信息等
rbd_object_map.( id ) | data | 记录组成image的所有数据对象的存在状态

#### RBD管理元数据
存储池级别用来记录和管理多个Image的元数据。

Rados对象名 | 元数据类型 | 描述
---|---|---
rbd_directory| omap | 记录存储池中所有的image列表
rbd_children | omap | 记录父image快照到克隆image之间的单向映射关系(parent --> children)

## 条带化介绍
rbd会将一个大的image分拆成多个object，数据会条带化的存储到后端Rados集群中，ceph默认不开启对象条带化。条带化类似 raid0，就是将raid0中的磁盘换成了对象。

下图为条带化示意图：

![条带化 示意图](/images/posts/rbd-条带化.png)

上图概念介绍
- 蓝色柱状：代表一个个rados底层对象，默认为4M
- 绿色块su：代表一个个条带话单元
- 红色框stripe: 代表一个个条带
- objectset代表对象组: 在cephfs中一般一个对象组属于同一个文件，在rbd中没有这种限制。

#### 条带化事例
- 概念介绍

```
object_size：对象的大小，就是rados底层对象的大小，一般默认是4M

stripe_unit: 条带每个su的大小

stripe_count：每个条带有多少个su, 跨域多少个底层object

stripes_per_object: 每个底层object对应多少个条带
```

- 条带化案例
rbd的源码中使用 file_to_extent 这个函数完成数据的条带化。file_to_extent函数把一维坐标转化成三维坐标(objectset，stripeno，stripepos)，这三维坐标分别表示哪一个objectset，哪一个stripe(条带)，条带中的哪一个su(对象分片)。

下图为条带化案例图：

![条带化案例](/images/posts/rbd-条带化例子.png)

上图假设一个对象的大小是3M，一个对象分片大小是1M，上图两个objectset占用6个rados的对象，总共有18个条带化对象分片。我们读取1M ~ 6M的相关数据，上图所示就需要读取分片su1 ~ su6 六个分片。具体变量如下：
```
offset: 1M 表示读偏移量
len: 6M 表示要读取的大小

object_size: 3M
stripe_unit: 1M
stripe_count: 3
stripes_per_object: 3
```

条带化后就会得到对应后端每个对象需要写入或者读取的偏移和长度，并将相关请求通过librados发送到后端集群。


### image request类图
![rbd image request类图](/images/posts/rbd-imagerequest.png)

### object request类图
![rbd object request类图](/images/posts/rbd-objectrq.png)

## 写流程介绍

## 读流程介绍

## object cache介绍